import { agentLoop, } from "@mariozechner/pi-ai";
/**
 * Transport that calls LLM providers directly.
 * Optionally routes calls through a CORS proxy if configured.
 */
export class ProviderTransport {
    options;
    constructor(options = {}) {
        this.options = options;
    }
    async *run(messages, userMessage, cfg, signal) {
        // Get API key
        let apiKey;
        if (this.options.getApiKey) {
            apiKey = await this.options.getApiKey(cfg.model.provider);
        }
        if (!apiKey) {
            throw new Error(`No API key found for provider: ${cfg.model.provider}`);
        }
        // Clone model and modify baseUrl if CORS proxy is enabled
        let model = cfg.model;
        if (this.options.corsProxyUrl && cfg.model.baseUrl) {
            model = {
                ...cfg.model,
                baseUrl: `${this.options.corsProxyUrl}/?url=${encodeURIComponent(cfg.model.baseUrl)}`,
            };
        }
        // Messages are already LLM-compatible (filtered by Agent)
        const context = {
            systemPrompt: cfg.systemPrompt,
            messages,
            tools: cfg.tools,
        };
        const pc = {
            model,
            reasoning: cfg.reasoning,
            apiKey,
            getQueuedMessages: cfg.getQueuedMessages,
        };
        // Yield events from agentLoop
        for await (const ev of agentLoop(userMessage, context, pc, signal)) {
            yield ev;
        }
    }
}
//# sourceMappingURL=ProviderTransport.js.map